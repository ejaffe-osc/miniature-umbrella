---
title: 'Jetstream2 launches large language model (LLM) inference service: News: News &amp; Events: Jetstream2: Indiana University'
---

<main><div class="content-top"><div class="section breadcrumbs"><div class="row"><div class="layout"><ul><li><a href="../../index.html">Home</a></li><li><a href="../index.html">News &amp; Events</a></li><li><a href="index.html">News</a></li><li class="current">Jetstream2 launches large language model (LLM) inference service</li></ul></div></div></div></div><div id="main-content"><div class="collapsed bg-none section" id="content"><div class="row"><div class="layout"><div class="detail-meta"><h1 class="no-margin h2" itemprop="headline">Jetstream2 launches large language model (LLM) inference service</h1><p class="meta" content="2025-04-11" itemprop="datePublished">Friday, April 11, 2025</p></div><!-- /.detail-meta --><div class="text"><p><span>Jetstream2 has recently unveiled a Large Language Model (LLM) inference service tailored to Jetstream2 users. This service provides access to advanced open-weight LLMs through two primary interfaces: a browser-based chat interface via Open WebUI similar to ChatGPT, and OpenAI-compatible inference APIs for seamless integration into various projects and applications.<br/><br/>The Jetstream2 inference service is especially valuable as it provides unlimited access to powerful large language models (LLMs) at no cost to researchers, educators, and students within the Jetstream2 community. Unlike LLMs running on personal machines or standard Jetstream2 instances, this service utilizes significantly larger and more capable models. Whether refining research papers, debugging code, brainstorming for projects, or summarizing complex texts, the Jetstream2 inference service can boost productivity and help facilitate innovation.<br/></span></p><p><span>Users can explore AI-driven workflows with confidence knowing that security and privacy are key considerations for the Jetstream2 inference service. All data is processed exclusively within the IU Bloomington Data Center, ensuring that user interactions remain confidential. Prompt and response data are encrypted in transit, and the system does not store conversations or use data for AI training.&#160;</span></p><p><span>Users can engage with the broader Jetstream2 community for support and collaboration by joining the&#160;<a class="external" href="https://matrix.to/#/#js2-inference-service:matrix.org" rel="noopener" target="_blank">inference-service channel</a>&#160;in the&#160;<a class="external" href="https://docs.jetstream-cloud.org/overview/status/?h=matrix#community-chat" rel="noopener" target="_blank">Jetstream2 community chat</a>. This space enables discussions on best practices, troubleshooting, and sharing ideas into how these LLMs can be effectively applied across various domains.<br/><br/>As the state of the art advances rapidly, the models offered are subject to change. Current models available include:</span></p><ul><li><span><strong>DeepSeek R1,</strong>&#160;a 671-billion-parameter chains-of-thought reasoning model</span></li><li><span><strong>Llama 4 Scout,</strong>&#160;our latest vision-language model</span></li><li><span><strong>Llama-3.3-70B-Instruct,</strong>&#160;a general-purpose instruct-tuned model</span></li></ul><p><span>To access the inference service and connect with other users, visit the <a href="https://docs.jetstream-cloud.org/inference-service/overview/" rel="noopener" target="_blank">Inference Service Overview page</a>.</span></p></div></div><!-- /.layout --></div></div></div>
                                
          
    
                    
        
    
            
                    </main>
